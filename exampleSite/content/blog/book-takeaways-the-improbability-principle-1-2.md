+++
author = ["Timothy Chung"]
categories = ["Psychology", "Statistics"]
date = 2020-08-13T16:00:00Z
description = ""
draft = true
image = "/images/img_0541.jpg"
tags = ["Philosophy", "Physics", "Probabilities", "Mathematics"]
title = "Book Takeaways: The Improbability Principle (1/2)"

+++
# The Improbability Principle

This is part one of my takeaways I've learnt from the book _The Improbability Principle_ by David J Hand. It explores the reasons behind why very rare things do occur. I've selected quotes and explanations from the book, paraphrased them and added my own findings to the mix. Enjoy!

# Introduction

* As humans, we are naturally curious and tend to be on the lookout for coincidences and patterns we find in everyday life.
* Of course, there are many interesting coincidences.
  * From Carl Jung’s _Synchronity_: Writer Wilhelm von Scholz tells the story of a mother who photographed her son in 1914 and sent the film to be developed in Strassburg. However war broke out and she could not retrieve it. Two years later, in Frankfurt, she bought a roll of film to photograph her daughter – when she developed the film she found another picture overlaid on the film – it was the photograph of her son in 1914! The old film must have been accidentally recirculated to be sold with the new films. \[1\]
  * Or Major Summerford, who was struck by lightning 3 times over the course of his life \[2\] – and lightning struck his gravestone as well. The probability of being struck by lightning outdoors is 1 in 750,000.

But perhaps coincidences are the reason behind our reality as we know it –

* (Darwin’s Theory of Evolution) Tiny random changes in DNA caused us to evolve from water-dwelling creatures into humans.
* (Maxwell’s Equations) Why is the speed of light exactly 299,792,458 m/s?

# Borel’s Law

> Events With A Sufficiently Small Probability Never Occur

Émile Borel, a French mathematician born in 1871, was a trailblazer for mathematical methods regarding probability.

**Borel’s Law** is in regards to the Infinite Monkey Theorem – a monkey who randomly presses letters on a typewriter, given an infinite amount of time would be able to reproduce any works of literature exactly, like the complete works of Shakespeare.

However, without an infinite amount of time, this event would could not be rationally demonstrated, and could be considered actually impossible. This law relates to probabilities so small that it would be irrational to witness it ever happen within the span of human existence. \[3\]

But this threshold still applies to the less far-fetched. Borel’s writes, “For every Parisian who circulates for one day, the probability of being killed in the course of the day in a traffic accident is about one-millionth. If, in order to avoid this slight risk, a man renounced all external activity and cloistered himself in his house, or imposed such confinement on his wife or his son, he would be considered mad.” \[4\]

Borel’s Law takes a practicality stance when it comes to probabilities – treat very tiny probabilities as if they were zero. He also gives a scale of negligence and names for each extent of improbability.

1. Negligible on the human scale: 1 in 650,000. One example of this is being dealt a royal flush in poker.
2. Negligible on the terrestrial scale: 1 in 10^15. One example is dividing the earth into square feet (earth’s surface area is 5.5 * 10^15 sqf). Suppose you and I choose one square foot at random, the probability of us choosing the same square would be on the terrestrial scale.
3. Negligible on the cosmic scale: 1 in 10^50. Earth has 10^50 atoms, so this probability is the same as two people randomly choosing the same atom on the Earth.
4. Negligible on the supercosmic scale: 1 in 10^1000,000,000. This is such a huge number; even greater than the number of subatomic particles in the universe. The book provides no examples for this.

# But Borel’s Law...

Yes, but the Improbability Principle tells us that highly unlikely events keep occurring. We still see them from time to time. Now this creates a contradiction.

# Things we get wrong as humans:

Humans are naturally curious and will look for patterns – however, sometimes, correlation does not mean causation.

1. “Hot hand” play. When players are on a winning streak, onlookers think that they are more likely to continue scoring higher than average, even though their performance is purely random. Numbers do repeat in sequences randomly – see point 6.
2. **Superstitions** such as walking under a ladder bringing bad luck. This could be due to a pot of paint dropped on you while walking underneath a ladder. A similar example would be the trivial rituals sports players undertake before starting a game. For example, a certain sock combination, a lucky hat, cutting fingernails at half-time.

   Once a superstition is established, they tend to strengthen on their own. This is due to **confirmation bias** – humans are not good at testing hypothesis easily as we only capitalise on evidence and events that support our theories.
3. **Prophecies**. Prophecies are not the same as predictions. Predictions are made from accumulated evidence and statistical methods of evaluation. Examples of predictions can be weather predictions based on wind speed, humidity, temperature, and season. But prophecies are based on uncertainties.

   Take Nostradamus’s prophecies, foretelling future natural disasters and wars, as an example. The reasons why some people believe his claims are legitimate are because of **confirmation bias** and **the law of near-enough.** I’ll cover on the latter cause, but for now, the name is self-explanatory – Prophecies are usually ambiguous and can be interpreted to be correct. Confirmation bias is at work here – his supporters only focus on/publish the prophecies he got right, leaving out the untrue prophecies, which actually outnumbered his correct prophecies.

   There are also self-fulfilling prophecies – a term coined by sociologist Robert K. Merton, for example, a student who believes he will fail an exam, will spend more time worrying than studying, which will affect his mental performance; he ends up failing the exam. \[5\]

   Optimists tend to put themselves in positions with favourable outcomes and the opposite happens for pessimists. But perhaps optimists spent more time looking for improvements in outcomes than their negative counterparts, and were more likely to find it.
4. **Conjunction Fallacy.**

   Read the following question.

   John is male. Which is more likely?

   A: John is married with two children.

   B: John is married with two children, enjoys fishing and playing computer games.

   Many people answer B as they percieve the combinations of two independent events are more likely than one event, even though B is a duplicate of A and more, which means the probability of B should be less than A.

   People are shaped by their stereotypes and biases, as they most likely came up with an image of John, a male, doing hobbies that are more male-oriented.
5. **Prosecutor's Fallacy.**

   There is a trial for a murder case – see the data below.
6. ![](/images/06a0862f-c421-4f5c-b0e7-ee52f00c0b25.jpeg)

   A defendant is at trial, being accused of the murder because his fingerprints were found at the scene.

   The probability of his innocence is 0.9, as there are 9 fingerprints out of 10.

   The probability of his fingers being at the scene (yet still innocent) would be 9/(7bn + 9)≈ 1.286*10^-9.

   Now, the judge might focus too much on the second probability because it would be a 1 in 77,777,7779 chance – very suspicious.

   But the more important probability we should focus on is the 0.9 value – he is more likely to be innocent!
7. We are not good at generating random numbers. If were asked to imitate a random number generator from 1-10 we would avoid repeating the same number, trying to balance everything out. Humans are not used to repeated digits in random sequences. Apple had a 'shuffle' feature on their iPods, and in 2008 some people complained that the shuffle wasn't 'random enough' \[7\], as they would hear songs from the same artist or album played consecutively. Although these sequences were expected from random list of songs, Apple had to tweak it so similar songs wouldn't play together.
8. Hindsight bias – It is easy to see the signs leading to an event once know it has happened. Take the 9/11 tragedy for example, it is possible to see the events hinting the attack, but that is in retrospect. There are simply too many combinations to fit the pieces together, but knowing the outcome makes it much easier to come up with a explanation. In fact, we see many inverse examples – people making confident predictions that with hindsight turned out to be the opposite.
   1. “The horse is here to stay, but the automobile is only a novelty, a fad.” – President of Michigan Savings Bank, advising Henry Ford’s lawyer not to invest in the Ford Motor Company
   2. “There is no reason for any individual to have a computer in his home.” – Ken Olson, president of the Digital Equipment Corporation
   3. “There’s no chance that the iPhone is going to get any significant market share.” Steve Ballmer, 2007

# Gambler’s fallacy

When tossing a coin repeatedly, in the event one side keeps getting tossed more than the other, many people expect the other side of the coin to have a higher chance of being tossed to ‘counterbalance‘ the disparity. However, this is not the case. What happens is that the later tosses should have roughly equal numbers of head and tails, and this equality dilutes the earlier disparity, given a large number of tosses.

# A Clockwork Universe

Pierre Simon, a 17th-century mathematician wrote:

> “An intelligence which, at a given instant, would know all the forces by which Nature is animated, and the respective situation of all the elements of which it is composed, if furthermore it were vast enough to submit all these data to analysis, would in the same formula encompass the motions of the largest bodies of the universe, and those of the most minute atom: nothing for it would be uncertain, and the future as well as the past would be present to its eyes.”

His view of nature is also known as as a _clockwork universe_ – describing a deterministic universe, progressing forward, ticking along a pre-determined route. The only obstacle hindering the prediction of natural phenomena was simply ignorance – or undiscovered conditions or situations masking the situation. As science advances, this ignorance would be eroded, e.g. with the advent of microscopes.

However, over the 20th century, this ironic theory, or rather, ignorance eroded away. Quantum physics became a debated new topic, and it seemed that the universe was run by random chance and uncertainties. The term chaos comes into place here.

Edward Lorenz, the founder of chaos theory, summarised this: ”Chaos: when the present determines the future, but the approximate present does not approximately determine the future.” \[7\]

We only have approximate knowledge about the present. The system of physics as we know it is an intrinsically unstable at its core – given the quantum properties of nature on an atomic scale. For example, trying to balance a pencil on its point. It will eventually fall, and the direction of how it falls is dependent on its minute differences in its position at the start. Also, think of cue balls on a snooker table – how they collide and rebound off each other is dependent on the angle of attack, speed, the surface of the table, and even the wear and tear on the stick and the cue ball. Minute differences in initial conditions will influence the outcome, making prediction impossible.

Then, we can never measure anything with perfect accuracy.

# Chaos: Randomness vs Predictability

Keep in mind that randomness and predictability are mutually exclusive. Randomness refers to the unpredictable, flow of events, or a notion of free will. Outcomes can be assigned different probabilities but it will be impossible to determine the sequence of the outcomes exactly.

Predictability, however, is the opposite of randomness – for example, we can predict a sequence of numbers generated by a chaotic system, provided we have complete knowledge of the system and the starting value. Another word for this ‘chaotic system’, in computer science, is also called a pseudorandom number generator.

# Law of Large Numbers

> The average of a sequence of numbers randomly drawn from a given set of values is likely to get closer and closer to the average of that set.

Consider the set of 6 values {1, 2, 3, 4, 5, 6}. They have an average of 3.5.

Supposing we choose randomly pick a number from the set (we don’t take it out, so we can pick it more than once.) The more we randomly pick out each number, the closer the average of the picks get to 3.5. We could generate a number by throwing a 6-sided die.

If you only pick out a few numbers, the average of the values start to jump around, for from the value of 3.5 we’re looking for. But gradually, as more throws are made, the more the average settles down and converges towards 3.5. We learn the proper terminology in A-Level Statistics; that the average of the picks is E(X)/n, where E(X) is the expected value of the throws added together and n is the number of throws. (Given that the probabilities are spread across a discrete uniform distribution).

# Central Limit Theorem

Imagine choosing values at random from the set {1, 2, 3, 4, 5, 6}, where the selection is done by a fair 6-sided die. Five values are to be drawn and their average calculated. Another 5 values are drawn and another average is also calculated. These two averages are likely to be different. Once we repeat the calculation of the averages many times, we end up with a distribution of averages for a sample size of five (which you could plot on a graph.)

Well, we could have used different sample sizes instead of 5. But the central limit theorem describes the shape of distribution that we would achieve as larger and larger sample sizes are used. This is known as the **normal** **distribution**, which takes the shape of a bell.

![](/images/6f933d89-070f-4e3b-b3aa-d0d0a5ba072b.jpeg)

(Diagram taken from The Improbability Principle by David J. Hand)

# The Law of Inevitability

> One out of all possible outcomes must occur.

Throwing a die must result with the number 1 to 6. However, this law becomes more useful when dealing with tiny probabilities, such as the lottery or the stock market.

Take this example: I pretend to be a stock-market analyst and I am mailing people my predictions for a certain stock in the stock market. There are two outcomes – it can either rise or fall. Let’s start with 1024 people. I tell half of them that the stock price will rise and the other half that the price will fall. If the stock price does rise, I would continue to stay in correspondence with the 512 who were told correctly that the price would rise – and ignore the 512 whom I gave the wrong prediction to. I would repeat this for 10 weeks.

Regardless of whatever happens to the price (rise or fall) there will always exist a group that was given the correct predictions so far – it’s just that the group gets halved and halved farther. At the end of 10 weeks, there will be left a group of one person who would have been told the correct prediction every time. He/She might assume I am a soothsayer able to predict the future, or that person just happened to be 1/1024 up/down configurations that turned out to be correct.

# Law of Truly Large Numbers

> With a large enough number of opportunities N, any event (regardless of how small its probability) has a probability of occurring in an N independent trials that tends towards 1.

Suppose I have a random number generator that generates numbers between 1-1000. If I run the random number generator 10,000 times the probability that a certain number (481) in that range does not show up is equal to 0.999^10000. (999/1000 choices)=0.999.

The probability of never getting 481 at all in 10,000 trials is equal to 0.0000451, or a 1 in 22173 chance. And 10,000 trials isn’t considered a _truly large_ number.

Take the 2009 Bulgarian Lottery for an example. The lottery made national headlines when the winning numbers were drawn, and they turned out to be the exact same winning numbers as last week’s – 4, 15, 23, 24, 35 and 42. \[8\]

This lottery was a 6/49 lottery, where a player chooses six numbers from 1-49 with no duplicates. If the numbers raffled matches the player’s number (regardless of order) the player wins the jackpot. There would be 49**C**6 combinations, or 13,983,816 possible choices for numbers.

If the lottery only ran twice, there would only be one possible pair (2**C**2 = 1),(1&2) that had the same numbers so the probability of a repeat same number set being chosen would be 1 in 13,983,816.

Keep in mind we are talking about repeated numbers based on the history of all numbers of the lottery, and not two consecutive correct draws (otherwise that probability would be the same as the one mentioned in the top paragraph.)

What if the lottery had been held 1000 times? That would mean 1000 draws of the numbers. This translates to 1000**C**2, or 499,500 possible pairs that could be found. (1&2, 1&3, 1&4...) The probability having two repeated draws would be (1/13,983,816_499,500) ≈ 0.036. Sounds plausible.

If the number of possible pairs exceeded the 13,983,816, you can guarantee that there would be a repeated draw eventually (once you exhaust the entire set of configurations the next draw will match any configuration that exists in the set).

Working backwards, once the lottery is held 4404 times, it is more than half likely that any two draws will match. At 5290 times, it is guaranteed any two draws will match. If a lottery is held bi-weekly, it would take 51 years for a guaranteed match – and we see the pattern here! The Bulgarian lottery held almost biweekly and was 52 years old at the time, which does line up with the 51 years value we calculated – accounting for some weeks where lotteries were not held such as public holidays.

The Bulgarian lottery was unique so that two consecutive sets of numbers were drawn – a coincidence of 1 in 13,983,816. But we need to take into account for all the countries around the world holding several many lotteries at once. Two consecutive sets of numbers were also drawn in North Carolina in 2007.

The Law of Truly Large Numbers goes to show that occurrence with small probabilities will happen, given enough possibilities.

However, this law is the reason for uncertainties in science research that are time-consuming to deal with– for example, the search for the Higgs boson particle. It involves lots of gleaning through data to detect evidence of the Higgs boson phenomenon which would be manifested in high numbers of particle count at a certain mass. However, we do not know if they were caused purely by chance or by the Higgs boson.

# The Law of Selection

Humans tend to hold on to things that fit their narrative, and marginalise events that oppose it. This is such the case relating to psychic mediums and prophecies. Take Jeane Dixon for example, a famous psychic who was a personal advisor to Nancy and Ronald Reagan. She made several correct predictions such as a Democrat winning the 1960s U.S. presidential election and the assassination of the president in 1960 – making her  However this was balanced against her (lesser known but equally if not more outlandish) wrong predictions that the Soviet Union would be the first to send a man to the moon and the Second World War in 1958. People only remembered her for her correct predictions, which is the reason why Jeane had a cult following. It’s more statistically likely she made many ambiguous claims where only a portion turned out to be true.

(In January 2020, she predicted 2020 would end an Armageddon. Let’s hope not.)

# Regression to the Mean

Sir Francis Galton was a cousin of Charles Darwin and a scientist. He noted that characteristics extreme in their parents are likely to be less extreme in their children. For example, two very tall parents would typically produce children, although relatively tall, that were nearer to the average than their parents. Similarly, two shorter parents were more likely to produce children shorter than average but taller than them.

It was easy to assume that there was some sort of biological mechanism pulling the offspring’s height back to the average, but this was purely the law of selection manifesting itself, resulting in the regression to the mean.

Let’s ask a group of 3600 people to throw a fair 6-sided die. You would expect about 600 of them to get a one, 600 people to get a two, etc...and 600 of them to get a six.

Now, let’s focus on the 600 who got a six. Get the 600 people to throw the dice again, and we would expect that only 100 of them would get a six on the second try.

If we focus on people who acquired six, which is above the average (3.5), it’s more likely the next number they throw will be closer to the average, or less than six. The opposite is seen for numbers thrown below the average – it is more likely the next value that is thrown is closer to the average, or larger than the previous throw.

This holds true as the law of large numbers is at work here – keep asking them to throw the numbers over time and the average of their throws will tend to 3.5.

The law of selection is also to blame for this phenomenon because Galton noticed that comparisons were being made with the taller and shorter parents on the more extreme ends of the spectrum.

To further elaborate, we are not dismissing that a person’s height is determined by chance alone; height is dependant on genetic and environmental factors. For sake of explanation, genetics determine height to a certain range.

This is why a pair of tall parents are perceived tall because they reached close to their maximum height in the height range.

Their child will inherit their genetics that account for a certain range in height – and it will simply be up to chance/environmental factors to decide whether the child occupies the upper or lower part of the height range.

# Selection/Publication Bias

Scientific journals are more preferable to be published when they successfully show a phenomenon, instead of those that fail to show one.

Editors prefer to publish journals that show things work.

Selection bias is also seen when scientists are inclined to prove that something works – for example, whether a drug can successfully treat a sample of patients.

If placebos are not accounted for, even if patients get better purely by chance, the drug trial will appear to be effective, even if it is not.

Because of publication bias, not all discoveries/studies are valid, and hence after a certain period findings from newer studies will refute or conflict with their older counterparts.

A group of scientific studies once studied links between whether eating breakfast or not led to weight gain. The general consensus was that eating breakfast in the morning would not influence weight gain, although most of the studies were published and funded by food manufacturing companies – and were conducted without double blinding \[10\]. Double blinding means that every participant and the scientist who collects the data are unaware of treatment procedures and hypotheses to minimise bias.

Another effect of the Law of Selction bias is the dropout bias in regards to clinical drug trials. It is not uncommon for patients to drop out of a clinical study. Sometimes patients drop out of the trials because they are starting to feel better early on and do not wish to stay in the study any longer. Their cases may not be tabulated, and as a result, may make the drug seem like it is not effective.

# The Probability Lever

On October 19, 1987, the S&P 500 stock price fell by 22.6% That days was also called Black Monday, the largest percentage drop in all history of the American Stock Market, that sparked fears of worldwide economic instability.

Sebastian Mallaby claimed that the probability of the plunge was 1 in 10^160. “In terms of the normal probability distribution, to put that probability into perspective, it meant that an event such as the crash would not be anticipated to occur even if the stock market were to remain open for twenty billion years, the upper end of the expected duration of the universe, or even if it were to be reopened for further sessions of twenty billion years following each of twenty successive big bangs.” \[10\]

Borel’s Law states that we should not see events as improbable as Mallaby’s example. Why did it occur? David J. Hand, the author fo the Improbability Principle, calls the hidden cause “the law of the probability lever.” \[12\]

> A slight change in circumstances can have a huge impact on probabilities.

Keep in mind the quote of Mallaby’s takes the normal distribution into account. When scientific theory does not match what is observed, there could be a few causes – either it was problems with data (measurement errors), or the theory/assumptions are not mistaken.

The normal distribution has very nice mathematical probabilities, making theories and predictions easy to calculate. However, measurements often follow the normal distribution to an approximate extent.



(Photo taken from The Improbability Principle by David J. Hand)

The book _The Improbability Principle_ introduces another distribution: The Cauchy distribution. Assume we have a children’s IQ test, and scoring 20 and above would be considered a ‘genius’ score.

The probability of scoring above 20 using the **normal** **distribution**, is 1.3*10^23, which is so small that Borel’s Law applies, and we do not expect this to happen.

However, the probability of scoring above 20 using the Cauchy distribution is 1 in 31, which is much more likely. 3 out of every 100 children would score above 20, making this a score that shouldn’t really be called a ‘genius’ score.

This shows that a slight change to the shape of distribution can greatly impact probabilities that are insignificant to the point that they might happen in everyday life.

Another way to name events is by using the sigma – for example, a 5-sigma event is the probability of getting a value 5 standard deviations smaller/larger than the mean(where the distribution curve peaks). Now compare the table below of probabilities in the normal and cauchy distributions.



(Photo taken from The Improbability Principle by David J. Hand)

The probability lever is related to chaos and the **butterfly effect.** Let’s take an example here.

Atoms are very, very tiny, and they collide extremely quickly. A gas molecule collides every 1/50,00,000 seconds on average – 5 billion collisions per second. Removing one electron rom the edge of the universe could affect how atoms in space collide, all the way to Earth and Earth's atmosphere, altering how oxygen molecules move in the air would completely change the path of oxygen molecules in the air you breathe after just 1/100,000,000 of a second.

Chaos, as described earlier, is extremely sensitive to initial conditions. And it is impossible to get the initial conditions exactly correct (it involves infinite decimal places of accuracy).

The double pendulum is another example of a chaotic system:



(Photo taken from [fouriestseries.tumblr.com](http://fouriestseries.tumblr.com/))

Changing the initial conditions a tiny bit will greatly alter the path and movement. It will be impossible to replicate the path of a double pendulum as the angle is continous (infinite decimal places of accuracy), although it is deterministic– you can theoretically predict the movement of the pendulumn from a given initial condition.

# My Probability or Yours?

Major Walter Summerford was struck by lightning thrice over twelve years of his life. His gravestone was struck in 1936, four years after his death.

The probability of being struck by lightning is 1 in 700,000. To be struck thrice in your lifetime and once more on your gravestone is virtually zero chance – but not for Summerford. He was an outdoor person – and every time he was struck by lightning he was outside walking around during a thunderstorm. The probability of him getting struck would massively increase if he was outdoors, compared to most people who spend a majority of time indoors. Couple that with a 2-billion population(at the time), there would be many people happening to be outside during a thunderstorm.

At the time of writing, there are 20,827,622 cases of the coronavirus and 747,584 deaths from coronavirus. Does my probability of dying from coronavirus equal the deaths over earth’s population? (747,584/7,594,000,000) ≈ 1 in 10158.

Most probably not. Otherwise, we would see much less deaths. The probability of dying from coronavirus would be greatly increased in the elderly and weaker patients with an underlying health conditions \[13\], and in the citizens of countries with less access to advanced health care. In a coronavirus-free country such as Montenegro, the probability would be almost zero.

# The Law of Near Enough

Let’s say we are trying to guess the output of a 100-sided die. I choose 42, and the dice rolls 43.

“Oh no, I guessed so close!”

The probability of guessing right is 1 in 100. But since 42,43, and 44 are accepted as ‘correct’ or ‘close’, we’ve tripled our probability of surprise.

When we relax our criteria of definition, we greatly the probability of an apparent coincidence.

This complements the **look-elsewhere effect** in physics, where scientists search for “bumps“ – an excess number of observations that contain a particular value, to prove a certain phenomenon. If they find no “bumps” for a value, they will extend the search for any “bumps” at any values.

This dramatically increases the chance of finding a “bump”, because its criteria has been relaxed.

What about conspiracy theorists claiming that the Egyptians were enlightened by some supernatural nature to build the Great Pyramid of Giza at 29.9792458˚N, which happen to be the same digits of the speed of light, 299792458m/s.

The Law of Near Enough is in play here. First, we can place the decimal place anywhere, and the coordinates given are too specific– we only need 4 decimal places 29.9729˚N to roughly pinpoint the location of the pyramid (The law of selection applies here too). It does not help that the pyramid is extremely large and Egyptians did not use metres or latitude coordinates in 2500B.C!

# Bayesianism, Science, and Religion

The Bayesian approach to believing things – eliminate the more improbable, and choose the outcome that is more probable. The great philosopher David Hume, wrote that “no testimony is sufficient to establish a miracle, unless the testimony be of such a kind, that its falsehood would be more miraculous, than the fact which it endeavours to establish“. \[14\]

Religion is absolute truth because it is faith in concrete and defined tenets. Science is about looking for explanations – but not for finding absolute truth. Science depends on probabilities – the collection of data and gaining greater and grater understanding. We may chance upon data or evidence that disproves what we already know. Conclusions are not set – truths are not absolute. This allows for science to adapt itself, improving its accuracy.

Now, a personal opinion from me – how do I tie science and my faith together? If we consider the perspective of science,

### REFERENCES

 1. Carl G Jung, “An Acausal Connecting Principle, in _Synchronicity,_ Vol 8. (New Jersey: Princeton University Press, 1960), 15
 2. T. Footman, in _Guinness World Records 2001_. Guinness World Records. (New York: Guinness World Record Ltd, 2000), 36
 3. Émile Borel, in _Probabilities and Life, trans. Maurice Baudin._ (New York: Dover Publications, 1962), 2–3.
 4. Ibid., 26.
 5. Robert K. Merton, _On Social Structure and Science_ (Chicago: University of Chicago Press, 1996), 196.
 6. Dax Hamman. _Apple Made Their Shuffle Feature Less Random, to Make It More Random._ DaxThink. 1-3-2017 [https://www.daxthink.com/think/2017/2/27/apple-made-itunes-shuffle-less-random-to-make-it-more-random](https://www.daxthink.com/think/2017/2/27/apple-made-itunes-shuffle-less-random-to-make-it-more-random)
 7. Lorenz, Edward N. 1963. "Deterministic non-periodic flow". _Journal of the Atmospheric Sciences. 20 (2): 130–141._
 8. Reuters, 2009. “Identical Lottery Draw Was Coincidence.” Reuters. 18-9-2009. [https://www.reuters.com/article/us-lottery/identical-lottery-draw-was-coincidence-idUSTRE58H4AM20090918](https://www.reuters.com/article/us-lottery/identical-lottery-draw-was-coincidence-idUSTRE58H4AM20090918)
 9. Kelloggs. "Best Start to the Day", Kelloggs. Accessed 5-8-2020. [https://www.kelloggs.com/en_US/nutrition/best-start-to-the-day.html](https://www.kelloggs.com/en_US/nutrition/best-start-to-the-day.html#3)
10. BMJ. "Effect of breakfast on weight and energy intake: systematic review and meta-analysis of randomised controlled trials", BMJ. 30-1-2019 [https://www.bmj.com/content/364/bmj.l42](https://www.bmj.com/content/364/bmj.l42)
11. Sebastian Mallaby. In _More Money Than God: Hedge Funds and the Making of a New Elite_ (New York: The Penguin Press, 2010), chapter 4.
12. David J Hand, “The Law of the Probability Lever”. _The Improbability Principle: Why Coincidences, Miracles, and Rare Events Happen Every Day_(New York: Scientific American / Farrer, Straus and Giroux ,2015), chapter 7.
13. WHO Europe. _Statement – Older people are at highest risk from COVID-19, but all must act to prevent community spread_, World Health Organisation. Published 2-4-2020, para 4-6. [https://www.euro.who.int/en/health-topics/health-emergencies/coronavirus-covid-19/statements/statement-older-people-are-at-highest-risk-from-covid-19,-but-all-must-act-to-prevent-community-spread](https://www.euro.who.int/en/health-topics/health-emergencies/coronavirus-covid-19/statements/statement-older-people-are-at-highest-risk-from-covid-19,-but-all-must-act-to-prevent-community-spread)
14. David Hume, _An Enquiry Concerning Human Understanding, 2nd ed_. (Indianapolis, IN: Hackett Publishing 1993), 77. First published 1777.